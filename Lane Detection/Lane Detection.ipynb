{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('camera_cal/calibration11.jpg')\n",
    "image_shape = img.shape\n",
    "print(image_shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caliberation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "fnames = glob.glob(\"camera_cal/calibration*.jpg\")\n",
    "\n",
    "for fname in fnames:\n",
    "    img = mpimg.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        \n",
    "# use the object and image points to caliberate the camera and compute the camera matrix and distortion coefficients\n",
    "ret, cameraMatrix, distortionCoeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image_shape[:2],None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Distortion Correction Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('camera_cal/calibration2.jpg')\n",
    "undistorted = cv2.undistort(img, cameraMatrix, distortionCoeffs, None, cameraMatrix)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients and color transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_thresholded_image(img):\n",
    "    \n",
    "    img = cv2.undistort(img, cameraMatrix, distortionCoeffs, None, cameraMatrix)\n",
    "    \n",
    "    # convert to gray scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    height, width = gray.shape\n",
    "    \n",
    "    # apply gradient threshold on the horizontal gradient\n",
    "    sx_binary = abs_sobel_thresh(gray, 'x', 10, 200)\n",
    "    \n",
    "    # apply gradient direction threshold so that only edges closer to vertical are detected.\n",
    "    dir_binary = dir_threshold(gray, thresh=(np.pi/6, np.pi/2))\n",
    "    \n",
    "    # combine the gradient and direction thresholds.\n",
    "    combined_condition = ((sx_binary == 1) & (dir_binary == 1))\n",
    "    \n",
    "    # R & G thresholds so that yellow lanes are detected well.\n",
    "    color_threshold = 150\n",
    "    R = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    color_combined = np.zeros_like(R)\n",
    "    r_g_condition = (R > color_threshold) & (G > color_threshold)\n",
    "    \n",
    "    \n",
    "    # color channel thresholds\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    S = hls[:,:,2]\n",
    "    L = hls[:,:,1]\n",
    "    \n",
    "    # S channel performs well for detecting bright yellow and white lanes\n",
    "    s_thresh = (100, 255)\n",
    "    s_condition = (S > s_thresh[0]) & (S <= s_thresh[1])\n",
    "    \n",
    "    # We put a threshold on the L channel to avoid pixels which have shadows and as a result darker.\n",
    "    l_thresh = (120, 255)\n",
    "    l_condition = (L > l_thresh[0]) & (L <= l_thresh[1])\n",
    "\n",
    "    # combine all the thresholds\n",
    "    # A pixel should either be a yellowish or whiteish\n",
    "    # And it should also have a gradient, as per our thresholds\n",
    "    color_combined[(r_g_condition & l_condition) & (s_condition | combined_condition)] = 1\n",
    "    \n",
    "    # apply the region of interest mask\n",
    "    mask = np.zeros_like(color_combined)\n",
    "    region_of_interest_vertices = np.array([[0,height-1], [width/2, int(0.5*height)], [width-1, height-1]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, [region_of_interest_vertices], 1)\n",
    "    thresholded = cv2.bitwise_and(color_combined, mask)\n",
    "    \n",
    "    return thresholded\n",
    "    \n",
    "    \n",
    "    \n",
    "def abs_sobel_thresh(gray, orient='x', thresh_min=0, thresh_max=255):\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    max_value = np.max(abs_sobel)\n",
    "    binary_output = np.uint8(255*abs_sobel/max_value)\n",
    "    threshold_mask = np.zeros_like(binary_output)\n",
    "    threshold_mask[(binary_output >= thresh_min) & (binary_output <= thresh_max)] = 1\n",
    "    return threshold_mask\n",
    "\n",
    "def dir_threshold(gray, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobel_x = np.absolute(sobel_x)\n",
    "    abs_sobel_y = np.absolute(sobel_y)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient\n",
    "    direction = np.arctan2(abs_sobel_y,abs_sobel_x)\n",
    "    direction = np.absolute(direction)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    mask = np.zeros_like(direction)\n",
    "    mask[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Binary Thresholded Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "thresholded = get_thresholded_image(img)\n",
    "img = cv2.undistort(img, cameraMatrix, distortionCoeffs, None, cameraMatrix)\n",
    "cv2.imwrite('thresholded.jpg',thresholded)\n",
    "\n",
    "# Plot the 2 images side by side\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(thresholded, cmap='gray')\n",
    "ax2.set_title('Thresholded Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vertices extracted manually for performing a perspective transform\n",
    "bottom_left = [220,720]\n",
    "bottom_right = [1110, 720]\n",
    "top_left = [570, 470]\n",
    "top_right = [722, 470]\n",
    "\n",
    "source = np.float32([bottom_left,bottom_right,top_right,top_left])\n",
    "\n",
    "pts = np.array([bottom_left,bottom_right,top_right,top_left], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "copy = img.copy()\n",
    "cv2.polylines(copy,[pts],True,(255,0,0), thickness=3)\n",
    "\n",
    "# Destination points are chosen such that straight lanes appear more or less parallel in the transformed image.\n",
    "bottom_left = [320,720]\n",
    "bottom_right = [920, 720]\n",
    "top_left = [320, 1]\n",
    "top_right = [920, 1]\n",
    "\n",
    "dst = np.float32([bottom_left,bottom_right,top_right,top_left])\n",
    "M = cv2.getPerspectiveTransform(source, dst)\n",
    "M_inv = cv2.getPerspectiveTransform(dst, source)\n",
    "img_size = (image_shape[1], image_shape[0])\n",
    "\n",
    "warped = cv2.warpPerspective(thresholded, M, img_size , flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(copy)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(warped, cmap='gray')\n",
    "ax2.set_title('Warped Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the lane pixels: Part 1\n",
    "\n",
    "\n",
    "## Histogram\n",
    "The peaks int the histogram tell us about the likely position of the lanes in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "histogram = np.sum(warped[warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "# Peak in the first half indicates the likely position of the left lane\n",
    "half_width = np.int(histogram.shape[0]/2)\n",
    "leftx_base = np.argmax(histogram[:half_width])\n",
    "\n",
    "# Peak in the second half indicates the likely position of the right lane\n",
    "rightx_base = np.argmax(histogram[half_width:]) + half_width\n",
    "\n",
    "print(leftx_base, rightx_base)\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the lane pixels: Part 2\n",
    "\n",
    "## Sliding Window Search\n",
    "\n",
    "we then perform a sliding window search, starting with the base likely positions of the 2 lanes, calculated from the histogram. \n",
    "\n",
    "The x & y coordinates of non zeros pixels are found, a polynomial is fit for these coordinates and the lane lines are drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_img = np.dstack((warped, warped, warped))*255\n",
    "\n",
    "non_zeros = warped.nonzero()\n",
    "non_zeros_y = non_zeros[0]\n",
    "non_zeros_x = non_zeros[1]\n",
    "\n",
    "num_windows = 10\n",
    "num_rows = warped.shape[0]\n",
    "window_height = np.int(num_rows/num_windows)\n",
    "window_half_width = 50\n",
    "\n",
    "min_pixels = 100\n",
    "\n",
    "left_coordinates = []\n",
    "right_coordinates = []\n",
    "\n",
    "for window in range(num_windows):\n",
    "    y_max = num_rows - window*window_height\n",
    "    y_min = num_rows - (window+1)* window_height\n",
    "    \n",
    "    left_x_min = leftx_base - window_half_width\n",
    "    left_x_max = leftx_base + window_half_width\n",
    "    \n",
    "    cv2.rectangle(out_img, (left_x_min, y_min), (left_x_max, y_max), [0,0,255],2)\n",
    "    \n",
    "    good_left_window_coordinates = ((non_zeros_x >= left_x_min) & (non_zeros_x <= left_x_max) & (non_zeros_y >= y_min) & (non_zeros_y <= y_max)).nonzero()[0]\n",
    "    left_coordinates.append(good_left_window_coordinates)\n",
    "    \n",
    "    if len(good_left_window_coordinates) > min_pixels:\n",
    "        leftx_base = np.int(np.mean(non_zeros_x[good_left_window_coordinates]))\n",
    "    \n",
    "    right_x_min = rightx_base - window_half_width\n",
    "    right_x_max = rightx_base + window_half_width\n",
    "    \n",
    "    cv2.rectangle(out_img, (right_x_min, y_min), (right_x_max, y_max), [0,0,255],2)\n",
    "    \n",
    "    good_right_window_coordinates = ((non_zeros_x >= right_x_min) & (non_zeros_x <= right_x_max) & (non_zeros_y >= y_min) & (non_zeros_y <= y_max)).nonzero()[0]\n",
    "    right_coordinates.append(good_right_window_coordinates)\n",
    "        \n",
    "    if len(good_right_window_coordinates) > min_pixels:\n",
    "        rightx_base = np.int(np.mean(non_zeros_x[good_right_window_coordinates]))\n",
    "        \n",
    "left_coordinates = np.concatenate(left_coordinates)\n",
    "right_coordinates = np.concatenate(right_coordinates)\n",
    "\n",
    "out_img[non_zeros_y[left_coordinates], non_zeros_x[left_coordinates]] = [255,0,0]\n",
    "out_img[non_zeros_y[right_coordinates], non_zeros_x[right_coordinates]] = [0,0,255]\n",
    "\n",
    "left_x = non_zeros_x[left_coordinates]\n",
    "left_y = non_zeros_y[left_coordinates]\n",
    "\n",
    "polyfit_left = np.polyfit(left_y, left_x, 2)\n",
    "\n",
    "right_x = non_zeros_x[right_coordinates]\n",
    "right_y = non_zeros_y[right_coordinates]\n",
    "\n",
    "polyfit_right = np.polyfit(right_y, right_x, 2)\n",
    "\n",
    "y_points = np.linspace(0, num_rows-1, num_rows)\n",
    "\n",
    "left_x_predictions = polyfit_left[0]*y_points**2 + polyfit_left[1]*y_points + polyfit_left[2]\n",
    "\n",
    "right_x_predictions = polyfit_right[0]*y_points**2 + polyfit_right[1]*y_points + polyfit_right[2]\n",
    "\n",
    "plt.imshow(out_img)\n",
    "plt.plot(left_x_predictions, y_points, color='yellow')\n",
    "plt.plot(right_x_predictions, y_points, color='yellow')\n",
    "plt.xlim(0, warped.shape[1])\n",
    "plt.ylim(warped.shape[0],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Identifying the lane pixels: Part 3\n",
    "\n",
    "## Searching around a previously detected line.\n",
    "\n",
    "Since consecutive frames are likely to have lane lines in roughly similar positions, in this section we search around a margin of 50 pixels of the previously detected lane lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "margin = 50\n",
    "out_img = np.dstack((warped, warped, warped))*255\n",
    "\n",
    "left_x_predictions = polyfit_left[0]*non_zeros_y**2 + polyfit_left[1]*non_zeros_y + polyfit_left[2]\n",
    "left_coordinates = ((non_zeros_x >= left_x_predictions - margin) & (non_zeros_x <= left_x_predictions + margin)).nonzero()[0]\n",
    "\n",
    "right_x_predictions = polyfit_right[0]*non_zeros_y**2 + polyfit_right[1]*non_zeros_y + polyfit_right[2]\n",
    "right_coordinates = ((non_zeros_x >= right_x_predictions - margin) & (non_zeros_x <= right_x_predictions + margin)).nonzero()[0]\n",
    "\n",
    "out_img[non_zeros_y[left_coordinates], non_zeros_x[left_coordinates]] = [255,0,0]\n",
    "out_img[non_zeros_y[right_coordinates], non_zeros_x[right_coordinates]] = [0,0,255]\n",
    "\n",
    "\n",
    "left_x = non_zeros_x[left_coordinates]\n",
    "left_y = non_zeros_y[left_coordinates]\n",
    "\n",
    "polyfit_left = np.polyfit(left_y, left_x, 2)\n",
    "\n",
    "right_x = non_zeros_x[right_coordinates]\n",
    "right_y = non_zeros_y[right_coordinates]\n",
    "\n",
    "polyfit_right = np.polyfit(right_y, right_x, 2)\n",
    "\n",
    "y_points = np.linspace(0, num_rows-1, num_rows)\n",
    "\n",
    "left_x_predictions = polyfit_left[0]*y_points**2 + polyfit_left[1]*y_points + polyfit_left[2]\n",
    "\n",
    "right_x_predictions = polyfit_right[0]*y_points**2 + polyfit_right[1]*y_points + polyfit_right[2]\n",
    "\n",
    "window_img = np.zeros_like(out_img)\n",
    "\n",
    "left_line_window_1 = np.array(np.transpose(np.vstack([left_x_predictions - margin, y_points])))\n",
    "\n",
    "left_line_window_2 = np.array(np.flipud(np.transpose(np.vstack([left_x_predictions + margin, y_points]))))\n",
    "\n",
    "left_line_points = np.vstack((left_line_window_1, left_line_window_2))\n",
    "\n",
    "cv2.fillPoly(window_img, np.int_([left_line_points]), [0,255, 0])\n",
    "\n",
    "right_line_window_1 = np.array(np.transpose(np.vstack([right_x_predictions - margin, y_points])))\n",
    "\n",
    "right_line_window_2 = np.array(np.flipud(np.transpose(np.vstack([right_x_predictions + margin, y_points]))))\n",
    "\n",
    "right_line_points = np.vstack((right_line_window_1, right_line_window_2))\n",
    "\n",
    "cv2.fillPoly(window_img, np.int_([right_line_points]), [0,255, 0])\n",
    "\n",
    "result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "plt.imshow(result)\n",
    "plt.plot(left_x_predictions, y_points, color='yellow')\n",
    "plt.plot(right_x_predictions, y_points, color='yellow')\n",
    "plt.xlim(0, warped.shape[1])\n",
    "plt.ylim(warped.shape[0],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the radius of curvature and center offset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def measure_radius_of_curvature(x_values):\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    # If no pixels were found return None\n",
    "    y_points = np.linspace(0, num_rows-1, num_rows)\n",
    "    y_eval = np.max(y_points)\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    fit_cr = np.polyfit(y_points*ym_per_pix, x_values*xm_per_pix, 2)\n",
    "    curverad = ((1 + (2*fit_cr[0]*y_eval*ym_per_pix + fit_cr[1])**2)**1.5) / np.absolute(2*fit_cr[0])\n",
    "    return curverad\n",
    "\n",
    "left_curve_rad = measure_radius_of_curvature(left_x_predictions)\n",
    "right_curve_rad = measure_radius_of_curvature(right_x_predictions)\n",
    "average_curve_rad = (left_curve_rad + right_curve_rad)/2\n",
    "curvature_string = \"Radius of curvature: %.2f m\" % average_curve_rad\n",
    "print(curvature_string)\n",
    "\n",
    "# compute the offset from the center\n",
    "lane_center = (right_x_predictions[719] + left_x_predictions[719])/2\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "center_offset_pixels = abs(img_size[0]/2 - lane_center)\n",
    "center_offset_mtrs = xm_per_pix*center_offset_pixels\n",
    "offset_string = \"Center offset: %.2f m\" % center_offset_mtrs\n",
    "print(offset_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Transfor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_img = np.dstack((warped, warped, warped))*255\n",
    "\n",
    "y_points = np.linspace(0, num_rows-1, num_rows)\n",
    "\n",
    "left_line_window = np.array(np.transpose(np.vstack([left_x_predictions, y_points])))\n",
    "\n",
    "right_line_window = np.array(np.flipud(np.transpose(np.vstack([right_x_predictions, y_points]))))\n",
    "\n",
    "line_points = np.vstack((left_line_window, right_line_window))\n",
    "\n",
    "cv2.fillPoly(out_img, np.int_([line_points]), [0,255, 0])\n",
    "\n",
    "unwarped = cv2.warpPerspective(out_img, M_inv, img_size , flags=cv2.INTER_LINEAR)\n",
    "\n",
    "result = cv2.addWeighted(img, 1, unwarped, 0.3, 0)\n",
    "\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Figuring out bad frames\n",
    "\n",
    "\n",
    "## Final Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some global variables\n",
    "polyfit_left=None\n",
    "polyfit_right=None\n",
    "\n",
    "past_good_left_lines = []\n",
    "past_good_right_lines = []\n",
    "\n",
    "running_mean_difference_between_lines = 0\n",
    "\n",
    "def get_line_predictions(non_zeros_x, non_zeros_y, left_coordinates, right_coordinates, num_rows):\n",
    "    \"\"\"\n",
    "        Given ncoordinates of non-zeros pixels and coordinates of non-zeros pixels within the sliding windows,\n",
    "        this function generates a prediction for the lane line.\n",
    "    \"\"\"\n",
    "    left_x = non_zeros_x[left_coordinates]\n",
    "    left_y = non_zeros_y[left_coordinates]\n",
    "    \n",
    "    # If no pixels were found return None\n",
    "    if(left_y.size == 0 or left_x.size == 0):\n",
    "        return None, None\n",
    "\n",
    "    # Fit the polynomial\n",
    "    polyfit_left = np.polyfit(left_y, left_x, 2)\n",
    "\n",
    "    right_x = non_zeros_x[right_coordinates]\n",
    "    right_y = non_zeros_y[right_coordinates]\n",
    "    \n",
    "    # If no pixels were found return None\n",
    "    if(right_y.size == 0 or right_x.size == 0):\n",
    "        return None, None\n",
    "\n",
    "    # Fit the polynomial\n",
    "    polyfit_right = np.polyfit(right_y, right_x, 2)\n",
    "\n",
    "    # If no pixels were found return None\n",
    "    y_points = np.linspace(0, num_rows-1, num_rows)\n",
    "    \n",
    "    # Generate the lane lines from the polynomial fit\n",
    "    left_x_predictions = polyfit_left[0]*y_points**2 + polyfit_left[1]*y_points + polyfit_left[2]\n",
    "    right_x_predictions = polyfit_right[0]*y_points**2 + polyfit_right[1]*y_points + polyfit_right[2]\n",
    "    \n",
    "    return left_x_predictions, right_x_predictions\n",
    "\n",
    "def brute_search(warped):\n",
    "    \"\"\"\n",
    "        This function searches for lane lines from scratch.\n",
    "        Thresholding & performing a sliding window search.\n",
    "    \"\"\"\n",
    "    non_zeros = warped.nonzero()\n",
    "    non_zeros_y = non_zeros[0]\n",
    "    non_zeros_x = non_zeros[1]\n",
    "    \n",
    "    num_rows = warped.shape[0]\n",
    "    \n",
    "    histogram = np.sum(warped[warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "    half_width = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:half_width])\n",
    "    rightx_base = np.argmax(histogram[half_width:]) + half_width\n",
    "\n",
    "    num_windows = 10\n",
    "    window_height = np.int(num_rows/num_windows)\n",
    "    window_half_width = 50\n",
    "\n",
    "    min_pixels = 100\n",
    "\n",
    "    left_coordinates = []\n",
    "    right_coordinates = []\n",
    "\n",
    "    for window in range(num_windows):\n",
    "        y_max = num_rows - window*window_height\n",
    "        y_min = num_rows - (window+1)* window_height\n",
    "\n",
    "        left_x_min = leftx_base - window_half_width\n",
    "        left_x_max = leftx_base + window_half_width\n",
    "\n",
    "        good_left_window_coordinates = ((non_zeros_x >= left_x_min) & (non_zeros_x <= left_x_max) & (non_zeros_y >= y_min) & (non_zeros_y <= y_max)).nonzero()[0]\n",
    "        left_coordinates.append(good_left_window_coordinates)\n",
    "\n",
    "        if len(good_left_window_coordinates) > min_pixels:\n",
    "            leftx_base = np.int(np.mean(non_zeros_x[good_left_window_coordinates]))\n",
    "\n",
    "        right_x_min = rightx_base - window_half_width\n",
    "        right_x_max = rightx_base + window_half_width\n",
    "\n",
    "        good_right_window_coordinates = ((non_zeros_x >= right_x_min) & (non_zeros_x <= right_x_max) & (non_zeros_y >= y_min) & (non_zeros_y <= y_max)).nonzero()[0]\n",
    "        right_coordinates.append(good_right_window_coordinates)\n",
    "\n",
    "        if len(good_right_window_coordinates) > min_pixels:\n",
    "            rightx_base = np.int(np.mean(non_zeros_x[good_right_window_coordinates]))\n",
    "\n",
    "    left_coordinates = np.concatenate(left_coordinates)\n",
    "    right_coordinates = np.concatenate(right_coordinates)\n",
    "    \n",
    "    left_x_predictions, right_x_predictions = get_line_predictions(non_zeros_x, non_zeros_y, left_coordinates, right_coordinates, num_rows)\n",
    "    return left_x_predictions, right_x_predictions\n",
    "\n",
    "def get_averaged_line(previous_lines, new_line):\n",
    "    \"\"\"\n",
    "        This function computes an averaged lane line by averaging over previous good frames.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of frames to average over\n",
    "    num_frames = 12\n",
    "    \n",
    "    if new_line is None:\n",
    "        # No line was detected\n",
    "        \n",
    "        if len(previous_lines) == 0:\n",
    "            # If there are no previous lines, return None\n",
    "            return previous_lines, None\n",
    "        else:\n",
    "            # Else return the last line\n",
    "            return previous_lines, previous_lines[-1]\n",
    "    else:\n",
    "        if len(previous_lines) < num_frames:\n",
    "            # we need at least num_frames frames to average over\n",
    "            previous_lines.append(new_line)\n",
    "            return previous_lines, new_line\n",
    "        else:\n",
    "            # average over the last num_frames frames\n",
    "            previous_lines[0:num_frames-1] = previous_lines[1:]\n",
    "            previous_lines[num_frames-1] = new_line\n",
    "            new_line = np.zeros_like(new_line)\n",
    "            for i in range(num_frames):\n",
    "                new_line += previous_lines[i]\n",
    "            new_line /= num_frames\n",
    "            return previous_lines, new_line\n",
    "        \n",
    "        \n",
    "def get_mean_distance_between_lines(left_line, right_line, running_average):\n",
    "    \"\"\"\n",
    "        Returns running weighted average of simple difference between left and right lines\n",
    "    \"\"\"\n",
    "    mean_distance = np.mean(right_line - left_line)\n",
    "    if running_average == 0:\n",
    "        running_average = mean_distance\n",
    "    else:\n",
    "        running_average = 0.9*running_average + 0.1*mean_distance\n",
    "    return running_average\n",
    "    \n",
    "\n",
    "def pipeline_final(img):\n",
    "    # global variables to store the polynomial coefficients of the line detected in the last frame\n",
    "    global polyfit_right\n",
    "    global polyfit_left\n",
    "    \n",
    "    # global variables to store the line coordinates in previous n (=4) frames\n",
    "    global past_good_right_lines\n",
    "    global past_good_left_lines\n",
    "    \n",
    "    # global variable which contains running average of the mean difference between left and right lanes\n",
    "    global running_mean_difference_between_lines\n",
    "    \n",
    "    img_shape = img.shape\n",
    "    img_size = (image_shape[1], image_shape[0])\n",
    "    \n",
    "    # get thresholded image\n",
    "    thresholded = get_thresholded_image(img)\n",
    "    \n",
    "    # perform a perspective transform\n",
    "    warped = cv2.warpPerspective(thresholded, M, img_size , flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    out_img = np.dstack((warped, warped, warped))*255\n",
    "    \n",
    "    non_zeros = warped.nonzero()\n",
    "    non_zeros_y = non_zeros[0]\n",
    "    non_zeros_x = non_zeros[1]\n",
    "    \n",
    "    num_rows = warped.shape[0]\n",
    "    y_points = np.linspace(0, num_rows-1, num_rows)\n",
    "    \n",
    "    if (polyfit_left is None) or (polyfit_right is None):\n",
    "        # If the polynomial coefficients of the previous frames are None then perform a brute force search\n",
    "        brute = True\n",
    "        left_x_predictions, right_x_predictions = brute_search(warped)\n",
    "    else:\n",
    "        # Else search in a margin of 100 pixels on each side of the pervious polynomial fit\n",
    "        brute = False\n",
    "        margin = 100\n",
    "        left_x_predictions = polyfit_left[0]*non_zeros_y**2 + polyfit_left[1]*non_zeros_y + polyfit_left[2]\n",
    "        left_coordinates = ((non_zeros_x >= left_x_predictions - margin) & (non_zeros_x <= left_x_predictions + margin)).nonzero()[0]\n",
    "\n",
    "        right_x_predictions = polyfit_right[0]*non_zeros_y**2 + polyfit_right[1]*non_zeros_y + polyfit_right[2]\n",
    "        right_coordinates = ((non_zeros_x >= right_x_predictions - margin) & (non_zeros_x <= right_x_predictions + margin)).nonzero()[0]\n",
    "        \n",
    "        left_x_predictions, right_x_predictions = get_line_predictions(non_zeros_x, non_zeros_y, left_coordinates, right_coordinates, num_rows)\n",
    "    \n",
    "    if (left_x_predictions is None or right_x_predictions is None):\n",
    "        if not brute:\n",
    "            left_x_predictions, right_x_predictions = brute_search(warped)\n",
    "            \n",
    "    bad_lines = False\n",
    "            \n",
    "    if (left_x_predictions is None or right_x_predictions is None):\n",
    "        bad_lines = True\n",
    "    else:\n",
    "        mean_difference = np.mean(right_x_predictions - left_x_predictions)\n",
    "        \n",
    "        if running_mean_difference_between_lines == 0:\n",
    "            running_mean_difference_between_lines = mean_difference\n",
    "        \n",
    "        if (mean_difference < 0.7*running_mean_difference_between_lines or mean_difference > 1.3*running_mean_difference_between_lines):\n",
    "            bad_lines = True\n",
    "            if not brute:\n",
    "                left_x_predictions, right_x_predictions = brute_search(warped)\n",
    "                if (left_x_predictions is None or right_x_predictions is None):\n",
    "                    bad_lines = True\n",
    "                else:\n",
    "                    mean_difference = np.mean(right_x_predictions - left_x_predictions)\n",
    "                    if (mean_difference < 0.7*running_mean_difference_between_lines or mean_difference > 1.3*running_mean_difference_between_lines):\n",
    "                        bad_lines = True\n",
    "                    else:\n",
    "                        bad_lines = False\n",
    "        else:\n",
    "            bad_lines = False\n",
    "            \n",
    "    if bad_lines:\n",
    "        polyfit_left = None\n",
    "        polyfit_right = None\n",
    "        if len(past_good_left_lines) == 0 and len(past_good_right_lines) == 0:\n",
    "            return img\n",
    "        else:\n",
    "            left_x_predictions = past_good_left_lines[-1]\n",
    "            right_x_predictions = past_good_right_lines[-1]\n",
    "    else:\n",
    "        past_good_left_lines, left_x_predictions = get_averaged_line(past_good_left_lines, left_x_predictions)\n",
    "        past_good_right_lines, right_x_predictions = get_averaged_line(past_good_right_lines, right_x_predictions)\n",
    "        mean_difference = np.mean(right_x_predictions - left_x_predictions)\n",
    "        running_mean_difference_between_lines = 0.9*running_mean_difference_between_lines + 0.1*mean_difference\n",
    "    \n",
    "    left_line_window = np.array(np.transpose(np.vstack([left_x_predictions, y_points])))\n",
    "    right_line_window = np.array(np.flipud(np.transpose(np.vstack([right_x_predictions, y_points]))))\n",
    "    \n",
    "    # compute the radius of curvature\n",
    "    left_curve_rad = measure_radius_of_curvature(left_x_predictions)\n",
    "    right_curve_rad = measure_radius_of_curvature(right_x_predictions)\n",
    "    average_curve_rad = (left_curve_rad + right_curve_rad)/2\n",
    "    curvature_string = \"Radius of curvature: %.2f m\" % average_curve_rad\n",
    "    \n",
    "    # compute the offset from the center\n",
    "    lane_center = (right_x_predictions[num_rows-1] + left_x_predictions[num_rows-1])/2\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    center_offset_pixels = abs(img_size[0]/2 - lane_center)\n",
    "    center_offset_mtrs = xm_per_pix*center_offset_pixels\n",
    "    offset_string = \"Center offset: %.2f m\" % center_offset_mtrs\n",
    "    \n",
    "    poly_points = np.vstack([left_line_window, right_line_window])\n",
    "    \n",
    "    cv2.fillPoly(out_img, np.int_([poly_points]), [0,255, 0])\n",
    "    \n",
    "    unwarped = cv2.warpPerspective(out_img, M_inv, img_size , flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    result = cv2.addWeighted(img, 1, unwarped, 0.3, 0)\n",
    "    \n",
    "    cv2.putText(result,curvature_string , (100, 90), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), thickness=2)\n",
    "    cv2.putText(result, offset_string, (100, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), thickness=2)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test2.jpg')\n",
    "\n",
    "# Reinitialize some global variables.\n",
    "polyfit_left = None\n",
    "polyfit_right = None\n",
    "past_good_right_lines = []\n",
    "past_good_left_lines = []\n",
    "running_mean_difference_between_lines = 0\n",
    "\n",
    "# Apply pipeline\n",
    "processed = pipeline_final(img)\n",
    "\n",
    "# Plot the 2 images\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(processed, cmap='gray')\n",
    "ax2.set_title('Processed Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  16%|█▌        | 203/1260 [00:53<04:27,  3.95it/s, now=None]"
     ]
    }
   ],
   "source": [
    "# Reinitialize some global variables.\n",
    "polyfit_left = None\n",
    "polyfit_right = None\n",
    "past_good_right_lines = []\n",
    "past_good_left_lines = []\n",
    "running_mean_difference_between_lines = 0\n",
    "\n",
    "\n",
    "output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline_final) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Video: Challenge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reinitialize some global variables.\n",
    "polyfit_left = None\n",
    "polyfit_right = None\n",
    "past_good_right_lines = []\n",
    "past_good_left_lines = []\n",
    "running_mean_difference_between_lines = 0\n",
    "\n",
    "\n",
    "output = 'challenge_video_output1.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline_final) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python [conda env:carnd]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
